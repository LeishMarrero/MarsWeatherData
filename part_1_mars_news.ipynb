{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 Challenge\n",
    "## Deliverable 1: Scrape Titles and Preview Text from Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 6.80M/6.80M [00:00<00:00, 7.28MB/s]\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Visit the Website\n",
    "\n",
    "1. Use automated browsing to visit the [Mars NASA news site](https://redplanetscience.com). Inspect the page to identify which elements to scrape.\n",
    "\n",
    "      > **Hint** To identify which elements to scrape, you might want to inspect the page by using Chrome DevTools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars NASA news site: https://redplanetscience.com\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)\n",
    "html = browser.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the Website\n",
    "\n",
    "Create a Beautiful Soup object and use it to extract text elements from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Beautiful Soup object\n",
    "soup = soup (html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the text elements\n",
    "textelements = soup.find_all('div', class_=\"list_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Store the Results\n",
    "\n",
    "Extract the titles and preview text of the news articles that you scraped. Store the scraping results in Python data structures as follows:\n",
    "\n",
    "* Store each title-and-preview pair in a Python dictionary. And, give each dictionary two keys: `title` and `preview`. An example is the following:\n",
    "\n",
    "  ```python\n",
    "  {'title': \"Mars Rover Begins Mission!\", \n",
    "        'preview': \"NASA's Mars Rover begins a multiyear mission to collect data about the little-explored planet.\"}\n",
    "  ```\n",
    "\n",
    "* Store all the dictionaries in a Python list.\n",
    "\n",
    "* Print the list in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the dictionaries\n",
    "titlelist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the text elements\n",
    "for text in textelements:\n",
    "# Extract the title and preview text from the elements\n",
    "    titles = text.find(\"div\", class_=\"content_title\").text\n",
    "    previewtext = text.find(\"div\", class_=\"article_teaser_body\").text\n",
    "# Store each title and preview pair in a dictionary\n",
    "    dictionary = {}\n",
    "    dictionary[\"title\"] = titles\n",
    "    dictionary[\"preview\"] = previewtext\n",
    "# Add the dictionary to the list\n",
    "    titlelist.append(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': \"NASA Engineers Checking InSight's Weather Sensors\", 'preview': 'An electronics issue is suspected to be preventing the sensors from sharing their data about Mars weather with the spacecraft.'}, {'title': 'NASA Prepares for Moon and Mars With New Addition to Its Deep Space Network', 'preview': 'Robotic spacecraft will be able to communicate with the dish using radio waves and lasers.'}, {'title': \"NASA's Perseverance Rover Will Peer Beneath Mars' Surface \", 'preview': \"The agency's newest rover will use the first ground-penetrating radar instrument on the Martian surface to help search for signs of past microbial life. \"}, {'title': \"NASA's MAVEN Observes Martian Night Sky Pulsing in Ultraviolet Light\", 'preview': 'Vast areas of the Martian night sky pulse in ultraviolet light, according to images from NASA’s MAVEN spacecraft. The results are being used to illuminate complex circulation patterns in the Martian atmosphere.'}, {'title': \"NASA's Mars 2020 Rover Goes Coast-to-Coast to Prep for Launch\", 'preview': \"The agency's first step in returning rocks from Mars just arrived at Kennedy Space Center. The Mars 2020 team now begins readying for a launch to the Red Planet this July.\"}, {'title': 'NASA Mars Mission Connects With Bosnian and Herzegovinian Town', 'preview': 'A letter from NASA was presented to the mayor of Jezero, Bosnia-Herzegovina, honoring the connection between the town and Jezero Crater, the Mars 2020 rover landing site.'}, {'title': 'Global Storms on Mars Launch Dust Towers Into the Sky', 'preview': 'A Mars Dust Tower Stands Out Dust storms are common on Mars. But every decade or so, something unpredictable happens: a series of runaway storms break out, covering the entire planet in a dusty haze.'}, {'title': \"Hear Audio From NASA's Perseverance As It Travels Through Deep Space\", 'preview': \"The first to be rigged with microphones, the agency's latest Mars rover picked up the subtle sounds of its own inner workings during interplanetary flight.\"}, {'title': \"A New Video Captures the Science of NASA's Perseverance Mars Rover\", 'preview': 'With a targeted launch date of July 30, the next robotic scientist NASA is sending to the to the Red Planet has big ambitions.'}, {'title': \"NASA's New Mars Rover Will Use X-Rays to Hunt Fossils\", 'preview': \"PIXL, an instrument on the end of the Perseverance rover's arm, will search for chemical fingerprints left by ancient microbes.\"}, {'title': \"All About the Laser (and Microphone) Atop Mars 2020, NASA's Next Rover\", 'preview': 'SuperCam is a rock-vaporizing instrument that will help scientists hunt for Mars fossils.'}, {'title': \"NASA's Perseverance Rover Goes Through Trials by Fire, Ice, Light and Sound\", 'preview': \"The agency's new Mars rover is put through a series of tests in vacuum chambers, acoustic chambers and more to get ready for the Red Planet.\"}, {'title': \"NASA InSight's 'Mole' Is Out of Sight\", 'preview': \"Now that the heat probe is just below the Martian surface, InSight's arm will scoop some additional soil on top to help it keep digging so it can take Mars' temperature.\"}, {'title': \"NASA's Curiosity Rover Finds an Ancient Oasis on Mars\", 'preview': \"New evidence suggests salty, shallow ponds once dotted a Martian crater — a sign of the planet's drying climate.\"}, {'title': \"NASA's Mars 2020 Heads Into the Test Chamber\", 'preview': 'In this time-lapse video taken at JPL, engineers move the Mars 2020 rover into a large vacuum chamber for testing in Mars-like environmental conditions.'}]\n"
     ]
    }
   ],
   "source": [
    "# Print the list to confirm success\n",
    "print(titlelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Step 4: Export the Data\n",
    "\n",
    "Optionally, store the scraped data in a file or database (to ease sharing the data with others). To do so, export the scraped data to either a JSON file or a MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to JSON\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(titlelist)\n",
    "df.to_json('titlelist.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to MongoDB\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
